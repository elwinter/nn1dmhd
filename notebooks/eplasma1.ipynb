{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "import math as m\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the run ID (aka problem name).\n",
    "runid = \"nn1dmhd.problems.eplasma1\"\n",
    "\n",
    "# Add the subdirectory for the run results to the module search path.\n",
    "run_path = os.path.join(\".\", runid)\n",
    "sys.path.append(run_path)\n",
    "\n",
    "# Import the problem definition from the run results directory.\n",
    "p = import_module(runid)\n",
    "\n",
    "# Read the run hyperparameters from the run results directory.\n",
    "import hyperparameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training points.\n",
    "xt_train = np.loadtxt(os.path.join(runid, \"xy_train.dat\"))\n",
    "x_train = xt_train[:, 0]\n",
    "t_train = xt_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the unique training point values.\n",
    "x_train_vals = x_train[::hp.ny_train]\n",
    "t_train_vals = t_train[:hp.ny_train]\n",
    "n_x_train_vals = len(x_train_vals)\n",
    "n_t_train_vals = len(t_train_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model-predicted values.\n",
    "Y = []\n",
    "delY = []\n",
    "for i in range(len(p.variable_names)):\n",
    "    var_name = p.variable_names[i]\n",
    "    Y.append(np.loadtxt(os.path.join(runid, \"%s_train.dat\" % var_name)))\n",
    "    delY.append(np.loadtxt(os.path.join(runid, \"del_%s_train.dat\" % var_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loss function histories.\n",
    "losses_model_all = np.loadtxt(os.path.join(runid, \"losses_model_all.dat\"))\n",
    "losses_model_bc = np.loadtxt(os.path.join(runid, \"losses_model_bc.dat\"))\n",
    "losses_model = np.loadtxt(os.path.join(runid, \"losses_model.dat\"))\n",
    "# <HACK>\n",
    "# Since there is only one model, add a dummy dimension for the model index.\n",
    "losses_model_all = losses_model_all[..., np.newaxis]\n",
    "losses_model_bc = losses_model_bc[..., np.newaxis]\n",
    "losses_model = losses_model[..., np.newaxis]\n",
    "# </HACK>\n",
    "losses_all = np.loadtxt(os.path.join(runid, \"losses_all.dat\"))\n",
    "losses_bc = np.loadtxt(os.path.join(runid, \"losses_bc.dat\"))\n",
    "losses = np.loadtxt(os.path.join(runid, \"losses.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute analytical solutions.\n",
    "Y_a = np.array([\n",
    "    p.n10*np.sin(p.kx*x_train - p.w*t_train)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the error in the predicted solutions relative to the analytical solutions.\n",
    "Y_err = Y - Y_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of models.\n",
    "n_models = len(p.variable_names)\n",
    "\n",
    "# Compute the number of rows for the 2-per-row plot.\n",
    "n_rows = m.ceil(n_models/2)\n",
    "\n",
    "# Compute the figure size for model loss plots, assuming 4x4 for each figure, in rows of 2 plots.\n",
    "loss_figsize = (10, 5)*n_rows\n",
    "\n",
    "# Compute the figure size for heat maps, assuming 6x4 for each figure, in rows of 2 plots.\n",
    "heatmap_figsize = (12, 4)*n_rows\n",
    "\n",
    "# Compute the figure size for the start-and-end comparison plots, in rows of 2 plots.\n",
    "start_end_figsize = (12, 4)*n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss history for each model.\n",
    "plt.figure(figsize=loss_figsize)\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[i]\n",
    "    plt.semilogy(losses_model_all[:, i], label=\"$L_{all,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model_bc[:, i], label=\"$L_{bc,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model[:, i], label=\"$L_{%s}$\" % variable_name)\n",
    "    plt.title(variable_name)\n",
    "    plt.legend()\n",
    "plt.suptitle(\"Loss function histories by model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total loss function history.\n",
    "plt.semilogy(losses_all, label=\"$L_{all}$\")\n",
    "plt.semilogy(losses_bc, label=\"$L_{bc}$\")\n",
    "plt.semilogy(losses, label=\"$L$\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Loss function evolution for %s\" % runid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the heat map tick locations and labels.\n",
    "n_x_ticks = 5\n",
    "n_t_ticks = 5\n",
    "x_tick_pos = np.linspace(0, n_x_train_vals - 1, n_x_ticks)\n",
    "x_tick_labels = [\"%.1f\" % (x/(n_x_train_vals - 1)) for x in x_tick_pos]\n",
    "t_tick_pos = np.linspace(0, n_t_train_vals - 1, n_t_ticks)\n",
    "t_tick_labels = [\"%.1f\" % (t/(n_t_train_vals - 1)) for t in t_tick_pos]\n",
    "t_tick_labels = reversed(t_tick_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model-predicted solutions.\n",
    "plt.figure(figsize=heatmap_figsize)\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[0]\n",
    "    # For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "    Z = np.flip(Y[i].reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "    ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "    plt.xticks(x_tick_pos, x_tick_labels)\n",
    "    plt.yticks(t_tick_pos, t_tick_labels)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"t\")\n",
    "    plt.title(variable_name)\n",
    "\n",
    "plt.suptitle(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analytical solutions.\n",
    "plt.figure(figsize=heatmap_figsize)\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[0]\n",
    "    # For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "    Z = np.flip(Y_a[i].reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "    ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "    plt.xticks(x_tick_pos, x_tick_labels)\n",
    "    plt.yticks(t_tick_pos, t_tick_labels)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"t\")\n",
    "    plt.title(variable_name)\n",
    "\n",
    "plt.suptitle(\"Analytical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error in the predicted solutions.\n",
    "plt.figure(figsize=heatmap_figsize)\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[0]\n",
    "    # For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "    Z = np.flip(Y_err[i].reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "    rms_err = np.sqrt(np.mean(Y_err**2))\n",
    "    ax = sns.heatmap(Z, vmin=-0.01, vmax=0.01)\n",
    "    plt.xticks(x_tick_pos, x_tick_labels)\n",
    "    plt.yticks(t_tick_pos, t_tick_labels)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"t\")\n",
    "    plt.title(\"%s, RMS error = %.1e\" % (variable_name, rms_err))\n",
    "\n",
    "plt.suptitle(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predicted and analytical solutions at start and end.\n",
    "plt.figure(figsize=start_end_figsize)\n",
    "for i in range(n_models):\n",
    "    variable_name = p.variable_names[0]\n",
    "\n",
    "    # Compare predicted and analytical values at the starting time.\n",
    "    plt.subplot(n_rows, 2, i*2 + 1)\n",
    "    x = x_train_vals\n",
    "    y = Y[i][0::hp.ny_train]\n",
    "    y_a = Y_a[i][0::hp.ny_train]\n",
    "    y_err = Y_err[i][0::hp.ny_train]\n",
    "    rms_err = np.sqrt(np.mean(y_err**2))\n",
    "    plt.plot(x, y, label=\"$%s_p$\" % var_name[i])\n",
    "    plt.plot(x, y_a, label=\"$%s_a$\" % var_name[i])\n",
    "    plt.plot(x, y_err, label=\"$%s_{err}$\" % var_name[i])\n",
    "    plt.ylim(-1.5*p.n10, 1.5*p.n10)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(\"t = %.1f, RMS err = %.1e\" % (p.t0, rms_err))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(var_name[i])\n",
    "\n",
    "    plt.subplot(n_rows, 2, i*2 + 2)\n",
    "    x = x_train_vals\n",
    "    y = Y[i][hp.ny_train - 1::hp.ny_train]\n",
    "    y_a = Y_a[i][hp.ny_train - 1::hp.ny_train]\n",
    "    y_err = Y_err[i][hp.ny_train - 1::hp.ny_train]\n",
    "    rms_err = np.sqrt(np.mean(y_err**2))\n",
    "    plt.plot(x, y, label=\"$%s_p$\" % var_name[i])\n",
    "    plt.plot(x, y_a, label=\"$%s_a$\" % var_name[i])\n",
    "    plt.plot(x, y_err, label=\"$%s_{err}$\" % var_name[i])\n",
    "    plt.ylim(-1.5*p.n10, 1.5*p.n10)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(\"t = %.1f, RMS err = %.1e\" % (p.t1, rms_err))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(var_name[i])\n",
    "\n",
    "plt.suptitle(\"Start and end comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('research-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2da49bfea38603819e913a4c68264bf8928db0e3621ba6c2bddf34624553e02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
